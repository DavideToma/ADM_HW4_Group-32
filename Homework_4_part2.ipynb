{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1 style=\"margin-top: 50px; font-size: 33px; text-align: center\">Homework 4 - Find the duplicates!</h1>\n",
    "    <br>\n",
    "    <div style=\"font-weight:200; font-size: 20px; padding-bottom: 15px; width: 100%; text-align: center;\">\n",
    "        <right>Davide Toma, Giacomo Lo Cascio, Musie Meressa </right>\n",
    "        <br>\n",
    "    </div>\n",
    "    <hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 steps that we have to perform:\n",
    "\n",
    "1. Convert the string containing the password to a (potentially large) number ** we created Convert_to_LargeNumber() that converts an ASCII of strings to large Number **.\n",
    "2. Use a hash function to map the number to a large range: ** We use Knuth Multiplication Hash from the book to hash the large number**.\n",
    "3. Detecting the duplicates: *** Here we use Pyspark to identify the duplicates.* Our Approach is to store the hash values into a file for each password. We count each Hash Number as a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "def Convert_to_LargeNumber(ASCII):\n",
    "        R = 2675\n",
    "        prod = 1\n",
    "        for  e in ASCII:\n",
    "                prod*=(R+2*e)\n",
    "        return(prod//2)     \n",
    "def HashFun(k): \n",
    "    w = 4294967295 # 2^32\n",
    "    A = 2654435769\n",
    "    r0 = k * A\n",
    "    p = 32\n",
    "    return ( r0 & w ) >> ( 32 - p ) # As stated in the book we use floor(m(kAmod1))\n",
    "\n",
    "passwords = open('passwords2.txt','r')\n",
    "\n",
    "f = open('HashValue2.txt','w+')\n",
    "\n",
    "for p in passwords:\n",
    "\n",
    "    list = [ord(char) for char in p.strip()]\n",
    "    \n",
    "    f.write(str(HashFun(Convert_to_LargeNumber(list)))+\"\\n\")\n",
    "\n",
    "passwords.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the HashValue using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HashValue = sc.textFile('HashValue2.txt') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Hash value as a word, and we count the number of occurences of each Hash Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccurenceCount = HashValue.flatMap(lambda line: line.split(\",\")).map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the duplicates we filter the hash values that are counted to be more than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duplicates = OccurenceCount.filter(lambda x: x[1]>1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10916162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Identify 10.9M duplicates from the passwords2.txt.\n",
    "\n",
    "Since we know there are 10 M false positives from the text, we get with our hash function 916.162 false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AABA != \"AAAB\n",
    "\n",
    "In this case we convert the ASCII values of each chararters sequentially. Therefore, two strings will be identicall if they have same characters. But for hashing we use same Hash Function as we did before. Finally, store the Hashed numbers into a file. ** The Steps are the same with the previous one.**. We get 6.1M duplicates for `AABA != AAAB`case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def Convert_to_LargeNumber(ASCII):\n",
    "        R = 265\n",
    "        a = []\n",
    "        for  e in ASCII:\n",
    "                a.append(e)\n",
    "        return (''.join(map(str,a))) # The two strings are indentical if their ascii are the same sequencially if not they are different\n",
    "\n",
    "    \n",
    "def HashFun(k):        \n",
    "    w = 4294967295 # 4294967296 # 2^32\n",
    "    A = 2654435769\n",
    "    r0 = k * A\n",
    "    p = 32\n",
    "    return ( r0 & w ) >> ( 32 - p ) # As stated in the book we use floor(m(kAmod1))\n",
    "\n",
    "passwords = open('passwords2.txt','r')\n",
    "\n",
    "f = open('HashValue5.txt','w+')\n",
    "\n",
    "for p in passwords:\n",
    "\n",
    "    list = [ord(char) for char in p.strip()]\n",
    "    \n",
    "    f.write(str(HashFun(int(Convert_to_LargeNumber(list))))+\"\\n\")\n",
    "\n",
    "passwords.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HashValue1 = sc.textFile('HashValue5.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OccurenceCount = HashValue1.flatMap(lambda line: line.split(\",\")).map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Duplicates1 = OccurenceCount.filter(lambda x: x[1]>1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6144841"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Duplicates1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we don't have the number of duplicates like the previous step, but based on the fact that our hash got some false positives in the step before, we know there are some false positives also in this part.\n",
    "\n",
    "The result is certainly acceptable, because in this case where the character position counts, we get less duplicates with our hash function than were present in case the character positions did not count (and so it was easier to have a False positive)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
